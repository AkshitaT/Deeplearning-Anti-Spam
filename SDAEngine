import org.canova.api.records.reader.RecordReader;
import org.canova.api.split.FileSplit;
import org.canova.nd4j.nlp.reader.TfidfRecordReader;
import org.deeplearning4j.datasets.canova.RecordReaderDataSetIterator;
import org.deeplearning4j.datasets.iterator.DataSetIterator;
import org.deeplearning4j.eval.Evaluation;
import org.deeplearning4j.nn.api.OptimizationAlgorithm;
import org.deeplearning4j.nn.conf.GradientNormalization;
import org.deeplearning4j.nn.conf.MultiLayerConfiguration;
import org.deeplearning4j.nn.conf.NeuralNetConfiguration;
import org.deeplearning4j.nn.conf.Updater;
import org.deeplearning4j.nn.conf.layers.AutoEncoder;
import org.deeplearning4j.nn.conf.layers.OutputLayer;
import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;
import org.deeplearning4j.nn.weights.WeightInit;
import org.deeplearning4j.optimize.api.IterationListener;
import org.deeplearning4j.optimize.listeners.ScoreIterationListener;
import org.nd4j.linalg.api.ndarray.INDArray;
import org.nd4j.linalg.dataset.DataSet;
import org.nd4j.linalg.lossfunctions.LossFunctions.LossFunction;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.File;
import java.util.Collections;


public class SDAEngine {

    private static Logger log = LoggerFactory.getLogger (SDAEngine.class);

    public static void main(String[] args) throws Exception {

        int outputNum = 2;
        int inputNum = 500;
        int iterations = 10;
        int seed = 123;
        int batchSize = 100;


        log.info ("Loading the train data....");
        Configuration config = new Configuration();
        config.setInt(TfidfVectorizer.MIN_WORD_FREQUENCY, 15);

        TfidfRecordReader readerTrain = new TfidfRecordReader();
        readerTrain.initialize (config, new FileSplit (new File ("Train/")));                           // Labeled path to the training vectors
        DataSetIterator trainIter = new RecordReaderDataSetIterator (readerTrain, batchSize);

        int inputNum = readerTrain.getNumFeatures();
        log.info(" Number of Features: " + inputNum);


        log.info ("Loading the test data...");
        TfidfRecordReader readerTest = new TfidfRecordReader ();
        readerTest.initialize (config, new FileSplit (new File ("Test/")));                             // Labeled path to the text vectors
        readerTest.setTfidfVectorizer(readerTrain.getTfidfVectorizer());                                                                       //reuse vectorizer
        DataSetIterator testIter = new RecordReaderDataSetIterator (readerTest, batchSize);


        log.info ("Build model....");
        MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder ()
                .seed (seed)
                .gradientNormalization (GradientNormalization.ClipElementWiseAbsoluteValue)
                .gradientNormalizationThreshold (1.0)
                .iterations (iterations)
                .updater (Updater.NESTEROVS)
                .momentum (0.5)
                .momentumAfter (Collections.singletonMap (3, 0.9))
                .optimizationAlgo (OptimizationAlgorithm.CONJUGATE_GRADIENT)
                .list ()
                .layer (0, new AutoEncoder.Builder ()
                        .nIn (inputNum)
                        .nOut (250)
                        .weightInit (WeightInit.XAVIER)
                        .lossFunction (LossFunction.RMSE_XENT)
                        .corruptionLevel (0.3)
                        .build ()
                )
                .layer (1, new AutoEncoder.Builder ()
                        .nIn (250)
                        .nOut (125)
                        .weightInit (WeightInit.XAVIER)
                        .lossFunction (LossFunction.RMSE_XENT)
                        .corruptionLevel (0.3)
                        .build ()
                )
                .layer (2, new AutoEncoder.Builder ()
                        .nIn (125)
                        .nOut (50)
                        .weightInit (WeightInit.XAVIER)
                        .lossFunction (LossFunction.RMSE_XENT)
                        .corruptionLevel (0.3)
                        .build ()
                )
                .layer (3, new OutputLayer.Builder (LossFunction.NEGATIVELOGLIKELIHOOD)
                        .activation ("softmax")
                        .nIn (75)
                        .nOut (outputNum)
                        .build ()
                )
                .pretrain (true)
                .backprop (false)
                .build ();


        MultiLayerNetwork model = new MultiLayerNetwork (conf);
        model.init ();
        model.setListeners (Collections.singletonList ((IterationListener) new ScoreIterationListener (1)));
        //model.setListeners(new HistogramIterationListener(1));        // Generating the Visualizing model


        log.info ("Train model....");
        try {
            model.fit (trainIter);
        } catch (Exception ex) {
            ex.printStackTrace();
        }


        log.info ("Evaluate model....");
        Evaluation eval = new Evaluation (outputNum);
        while (testIter.hasNext ()) {
            DataSet t = testIter.next ();
            INDArray features = t.getFeatureMatrix ();
            INDArray labels = t.getLabels ();
            INDArray predicted = model.output (features, false);
            eval.eval (labels, predicted);                          // Comparing the label predicted with the original label of the test data
        }


        log.info (eval.stats ());
        log.info ("**************** FINISH ********************");

    }
}
